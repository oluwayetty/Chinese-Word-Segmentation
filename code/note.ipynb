{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Tests",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "jl1irSJJdYtp",
        "colab_type": "code",
        "outputId": "af039607-fb51-4a1d-ee25-0c9552e9c267",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.version"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.6.7 (default, Oct 22 2018, 11:32:17) \\n[GCC 8.2.0]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "x99YBAu-dmzP",
        "colab_type": "code",
        "outputId": "43ad4154-6b2b-4da0-e396-8eaaf5f82941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# !pip install tensorflow==1.12.0\n",
        "# !pip install paramiko\n",
        "import tensorflow\n",
        "print(tensorflow.keras.__version__)\n",
        "print(tensorflow.__version__)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.4-tf\n",
            "1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gmMBwfsheETI",
        "colab_type": "code",
        "outputId": "74877216-5588-486e-8e2b-aea2495005c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-J0vqU6PqzLt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "import numpy as np\n",
        "import pickle  \n",
        "import time  \n",
        "import json\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, Bidirectional, Activation, LSTM,Dropout, InputLayer\n",
        "from gensim.models import KeyedVectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Thqn4kDZsh41",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from keras.models import model_from_json\n",
        "\n",
        "df = pandas.read_table('/content/gdrive/My Drive/yetty/data/all/onegram_input.utf8', header=None)\n",
        "label = pandas.read_table('/content/gdrive/My Drive/yetty/data/all/onegram_label.txt', header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rt6FD1Ynsj1a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df['label'] = label[0]\n",
        "df.columns = ['character', 'label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MMQxxIdpslMT",
        "colab_type": "code",
        "outputId": "9611c498-38c2-47b8-cb34-b34963b65c84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "df = df.sample(50000)\n",
        "df.sample(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>character</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2854408</th>\n",
              "      <td>，</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14390050</th>\n",
              "      <td>、</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13981445</th>\n",
              "      <td>健</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9419187</th>\n",
              "      <td>济</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4643829</th>\n",
              "      <td>主</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         character label\n",
              "2854408          ，     S\n",
              "14390050         、     S\n",
              "13981445         健     B\n",
              "9419187          济     E\n",
              "4643829          主     E"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "D3L2YxvzsrZi",
        "colab_type": "code",
        "outputId": "8ce9491f-7e68-4367-9c20-15fb41c4986c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "### Create sequence\n",
        "\n",
        "vocabulary_size = 128\n",
        "\n",
        "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
        "tokenizer.fit_on_texts(df['character'])\n",
        "sequences = tokenizer.texts_to_sequences(df['character'])\n",
        "data = pad_sequences(sequences, maxlen=50)\n",
        "\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "LHU23lpys4Ba",
        "colab_type": "code",
        "outputId": "6cb54837-404f-48d4-f64b-03459d33e8c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "labels = LabelEncoder().fit_transform(df.label)\n",
        "labels[:54]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 3, 1, 1, 0, 1, 3, 3, 0, 3, 2, 3, 0, 1, 3, 3, 1, 1, 0, 1, 0,\n",
              "       0, 1, 3, 3, 0, 3, 1, 1, 1, 3, 2, 2, 1, 0, 3, 1, 1, 1, 1, 1, 0, 2,\n",
              "       0, 1, 3, 1, 1, 2, 0, 1, 3, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "Vvq-vaxBs6iK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.33, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AzIiYq682ibu",
        "colab_type": "code",
        "outputId": "46d9868b-a530-4068-8748-de5040950b31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((33500, 50), (33500,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "BcROEMkps8dp",
        "colab_type": "code",
        "outputId": "06017d36-e2b9-4938-c5e2-4c39ff94cea2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "####Load Embedding\n",
        "embedding_model = KeyedVectors.load_word2vec_format('/content/gdrive/My Drive/yetty/data/all/allwang.txt')\n",
        "embedding_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x7efe0a763240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "Klcp-nmytAgI",
        "colab_type": "code",
        "outputId": "ae4dc843-1a16-4edf-f5aa-9bcb58e338d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "embedding_dim = len(embedding_model[next(iter(embedding_model.vocab))])\n",
        "embedding_dim"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "fbP-eBLgtDDQ",
        "colab_type": "code",
        "outputId": "bc159b21-dc9a-449d-d9df-e4bc73ce8a47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.random.rand(128, embedding_dim)\n",
        "embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.67334653, 0.25330103, 0.58441488, ..., 0.85212844, 0.41106069,\n",
              "        0.91684802],\n",
              "       [0.61443696, 0.35317711, 0.3937818 , ..., 0.35112873, 0.26156577,\n",
              "        0.88438597],\n",
              "       [0.55450353, 0.43587813, 0.12483314, ..., 0.89894735, 0.62546321,\n",
              "        0.95531268],\n",
              "       ...,\n",
              "       [0.37857429, 0.00348981, 0.82636624, ..., 0.90617931, 0.34458512,\n",
              "        0.35262095],\n",
              "       [0.13894049, 0.00141334, 0.23965882, ..., 0.53071724, 0.85242345,\n",
              "        0.96849986],\n",
              "       [0.38485477, 0.90038657, 0.86060933, ..., 0.08517784, 0.86481835,\n",
              "        0.22881968]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "_Jmf6WGDtJHB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def precision(y_true, y_pred):\t\n",
        "    \"\"\"Precision metric.\t\n",
        "    Only computes a batch-wise average of precision. Computes the precision, a\n",
        "    metric for multi-label classification of how many selected items are\n",
        "    relevant.\n",
        "    \"\"\"\t\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\t\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\t\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\t\n",
        "    return precision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tKlgw8_vtKrq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CLASSES = 4\n",
        "max_len = 50\n",
        "word_size = 100\n",
        "\n",
        "def build_model(char_size, dropout, lr, optimizer):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(char_size, word_size, input_length=max_len, weights=[embedding_matrix]))\n",
        "    model.add(Bidirectional(LSTM(char_size, dropout=dropout, recurrent_dropout=dropout, return_sequences=False), merge_mode='sum'))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add((Dense(CLASSES, activation='softmax')))\n",
        "    sgd = optimizers.SGD(lr=lr, momentum=0.95)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[precision, 'accuracy'])\n",
        "    return model\n",
        "  \n",
        "  \n",
        "model = KerasClassifier(build_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GYEwKSdgtSDw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save(model):  \n",
        "    timestring = \"\".join(str(time.time()).split(\".\"))  ###Save each epoch with a timestamp\n",
        "    model_json_name = '/content/gdrive/My Drive/yetty/data/all/resources/modelnew_{}.json'.format(timestring)\n",
        "    model_json = model.model.to_json()\n",
        "    with open(model_json_name, \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "    return model_json\n",
        "  \n",
        "  \n",
        "def get_metrics(y_pred, y_true):  \n",
        "    chosen_metrics = {\n",
        "        'accuracy': metrics.accuracy_score,\n",
        "        'precision' : metrics.precision_score\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "    for metric_name, metric_func in chosen_metrics.items():\n",
        "        try:\n",
        "            if metric_name == \"precision\":\n",
        "                inter_res = metric_func(y_pred, y_true, average=None)\n",
        "            else:\n",
        "                inter_res = metric_func(y_pred, y_true)\n",
        "        except Exception as ex:\n",
        "            inter_res = None\n",
        "            print(\"Couldn't evaluate %s because of %s\", metric_name, ex)\n",
        "        results[metric_name] = inter_res\n",
        "    return results\n",
        "\n",
        "\n",
        "def scorer_callback(model, X, y):  \n",
        "    # do all the work and return some of the metrics\n",
        "\n",
        "    y_pred_val = model.predict(X)\n",
        "    results = get_metrics(y_pred_val, y)\n",
        "    model_savepath = save(model)\n",
        "    return results['accuracy']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4_duCcrztUxZ",
        "colab_type": "code",
        "outputId": "7d59b663-c77f-4d00-dc39-1aca7d33bf76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "cell_type": "code",
      "source": [
        "params_dict = {\n",
        "    'lr': [0.04, 0.035],\n",
        "    'char_size': [128],\n",
        "    'dropout': [0.15, 0.25],\n",
        "    'optimizer': ['sgd'],\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(model,\n",
        "                    cv=2,\n",
        "                    param_grid=params_dict,\n",
        "                    return_train_score=True,\n",
        "                    scoring=scorer_callback)\n",
        "\n",
        "\n",
        "grid_results = grid.fit(X_train,y_train)\n",
        "\n",
        "print('Parameters of the best model: ')\n",
        "print(grid_results.best_params_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "16750/16750 [==============================] - 220s 13ms/step - loss: 1.2835 - precision: 0.1807 - acc: 0.3436\n",
            "Epoch 1/1\n",
            "16750/16750 [==============================] - 220s 13ms/step - loss: 1.2839 - precision: 0.2064 - acc: 0.3507\n",
            "Epoch 1/1\n",
            "16750/16750 [==============================] - 219s 13ms/step - loss: 1.2836 - precision: 0.1803 - acc: 0.3519\n",
            "Epoch 1/1\n",
            "16750/16750 [==============================] - 219s 13ms/step - loss: 1.2865 - precision: 0.1988 - acc: 0.3414\n",
            "Epoch 1/1\n",
            "16750/16750 [==============================] - 223s 13ms/step - loss: 1.3023 - precision: 0.2993 - acc: 0.3374\n",
            "Epoch 1/1\n",
            "16750/16750 [==============================] - 220s 13ms/step - loss: 1.3003 - precision: 0.3026 - acc: 0.3404\n",
            "Epoch 1/1\n",
            "16750/16750 [==============================] - 221s 13ms/step - loss: 1.3068 - precision: 0.3394 - acc: 0.3300\n",
            "Epoch 1/1\n",
            "16750/16750 [==============================] - 223s 13ms/step - loss: 1.3069 - precision: 0.3310 - acc: 0.3373\n",
            "Epoch 1/1\n",
            "33500/33500 [==============================] - 435s 13ms/step - loss: 1.2770 - precision: 0.3866 - acc: 0.3623\n",
            "Parameters of the best model: \n",
            "{'char_size': 128, 'dropout': 0.25, 'lr': 0.04, 'optimizer': 'sgd'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xJfpib8gttHI",
        "colab_type": "code",
        "outputId": "fe7b1b8f-cc88-427b-8a2b-bf0858ae878c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "grid.best_score_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.43334328358208957"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "A-12QWZUZcE0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t = grid.best_estimator_.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XcYHFLFsZo7r",
        "colab_type": "code",
        "outputId": "b4fb9b4a-1a59-4418-8585-ae4b309ec7fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "t.shape\n",
        "set(t)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "metadata": {
        "id": "o7qBF6_3aD8v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "u = np.argmax(l, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H51td3bIaIMv",
        "colab_type": "code",
        "outputId": "a70d5573-4292-42e1-ca76-34624ec4e273",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "u.shape, t.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6600,), (6600,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "y6k-ci-naI5v",
        "colab_type": "code",
        "outputId": "9a006366-9d58-48f4-de1d-873c331d5f61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "u[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "yN3VtPV8aMD3",
        "colab_type": "code",
        "outputId": "b68ceca4-a243-4403-992f-249adba8686b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        " t[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "metadata": {
        "id": "QQzDzlkqaOzG",
        "colab_type": "code",
        "outputId": "fbdd28d1-5940-41d7-d782-e8a292ca81cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "(u==t).all()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "metadata": {
        "id": "rPnkLxBOaStm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_json = grid.best_estimator_.model.to_json()\n",
        "with open(\"/content/gdrive/My Drive/yetty/data/all/resources/grid_model.json\", \"w\") as file:\n",
        "    file.write(model_json)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dJ9m0uoAaeSz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "grid.best_estimator_.model.save_weights('/content/gdrive/My Drive/yetty/data/all/resources/weights/grid_weights.h5', overwrite=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9xplu1b-aqg7",
        "colab_type": "code",
        "outputId": "bb526f96-2e0c-4619-908d-8d1c56756cbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# @title\n",
        "from tensorflow.keras.models import model_from_json\n",
        "    \n",
        "    \n",
        "loaded_model = model_from_json(open('/content/gdrive/My Drive/yetty/data/all/resources/grid_model.json').read())\n",
        "\n",
        "\n",
        "# load weights into new model\n",
        "loaded_model.load_weights('/content/gdrive/My Drive/yetty/data/all/resources/weights/grid_weights.h5',)\n",
        "print(\"Loaded model from disk\")\n",
        "\n",
        "loaded_model.compile(loss='categorical_crossentropy', optimizer='sgd')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Vav1kil4axVB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "d = loaded_model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-frT7Rt148gn",
        "colab_type": "code",
        "outputId": "8edceead-52cb-4de7-99de-84ca4e6552fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X = d\n",
        "X"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "metadata": {
        "id": "526y_KaZa2mh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "c = np.argmax(d, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_2JsrysGbCuv",
        "colab_type": "code",
        "outputId": "5ea4afd7-27c2-40e6-b1b5-3b73af6b1e2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "(c == X).all()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "metadata": {
        "id": "WPXdD6JKbndO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}