{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.6-tf\n",
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "print(tensorflow.keras.__version__)\n",
    "print(tensorflow.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow==1.12.0\n",
    "# !pip install gensim\n",
    "#!pip install pandas sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import pickle  \n",
    "import time  \n",
    "import json\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, Bidirectional, Activation, LSTM,Dropout, InputLayer\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_table('./data/asmsr/unigram_input.utf8', header=None)\n",
    "label = pandas.read_table('./data/asmsr/unigram_label.txt', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12418519, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = label[0]\n",
    "df.columns = ['character', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>人</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>们</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>常</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>说</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  character label\n",
       "0         “     S\n",
       "1         人     B\n",
       "2         们     E\n",
       "3         常     S\n",
       "4         说     S"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12418519, 50)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Create sequence\n",
    "\n",
    "vocabulary_size = 128\n",
    "\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "tokenizer.fit_on_texts(df['character'])\n",
    "sequences = tokenizer.texts_to_sequences(df['character'])\n",
    "data = pad_sequences(sequences, maxlen=50)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 1, 3, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = LabelEncoder().fit_transform(df.label)\n",
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12418519,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8320407, 50), (8320407,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x1231d6550>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####Load Embedding\n",
    "embedding_model = KeyedVectors.load_word2vec_format('./data/asmsr/wang.txt')\n",
    "embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = len(embedding_model[next(iter(embedding_model.vocab))])\n",
    "embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36236937, 0.13579486, 0.37293746, ..., 0.63957408, 0.64697332,\n",
       "        0.69093361],\n",
       "       [0.23546561, 0.46767522, 0.16060438, ..., 0.37154723, 0.6736566 ,\n",
       "        0.04704969],\n",
       "       [0.0251205 , 0.32985056, 0.31671518, ..., 0.71157356, 0.54858831,\n",
       "        0.3097355 ],\n",
       "       ...,\n",
       "       [0.98849906, 0.54533457, 0.69901819, ..., 0.66508425, 0.11274037,\n",
       "        0.02664581],\n",
       "       [0.3132925 , 0.91735305, 0.72715888, ..., 0.1536537 , 0.06369135,\n",
       "        0.0883931 ],\n",
       "       [0.51778437, 0.93261935, 0.20276315, ..., 0.70576082, 0.86636102,\n",
       "        0.98828809]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = np.random.rand(256, embedding_dim)\n",
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i < vocabulary_size:\n",
    "        try:\n",
    "          embedding_vector = embedding_model.get_vector(word)\n",
    "          embedding_matrix[i] = embedding_vector\n",
    "        except:\n",
    "          pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\t\n",
    "    \"\"\"Precision metric.\t\n",
    "    Only computes a batch-wise average of precision. Computes the precision, a\n",
    "    metric for multi-label classification of how many selected items are\n",
    "    relevant.\n",
    "    \"\"\"\t\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\t\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\t\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\t\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = 4\n",
    "max_len = 50\n",
    "word_size = 100\n",
    "\n",
    "def build_model(char_size, dropout, lr, optimizer):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(char_size, word_size, input_length=max_len, weights=[embedding_matrix]))\n",
    "    \n",
    "    model.add(LSTM(char_size, dropout=dropout, recurrent_dropout=dropout, return_sequences=True,name='backward_lstm')) \n",
    "    \n",
    "    model.add(LSTM(char_size, dropout=dropout, recurrent_dropout=dropout, return_sequences=False, name='forward_lstm')) \n",
    "    \n",
    "    model.add(Dropout(dropout))\n",
    "    model.add((Dense(CLASSES, activation='softmax')))\n",
    "    sgd = optimizers.SGD(lr=lr)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=[precision, 'accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y = to_categorical(y_train, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8320407, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5574672 samples, validate on 2745735 samples\n",
      "Epoch 1/1\n",
      "  30130/5574672 [..............................] - ETA: 91:24:34 - loss: 1.2400 - precision: 0.2414 - acc: 0.4027"
     ]
    }
   ],
   "source": [
    "filepath=\"/Users/oluwayetty1/Downloads/weights-improvement-{epoch:02d}-{precision:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor=precision, verbose=1, save_best_only=True, mode='max')\n",
    "csv_logger = CSVLogger('/Users/oluwayetty1/Downloads/training.log', separator=',', append=False)\n",
    "callbacks_list = [checkpoint,csv_logger]\n",
    "\n",
    "model = build_model(256, 0.15, 0.04, 'adam')\n",
    "\n",
    "history = model.fit(X_train, y, validation_split=0.33, epochs=1, batch_size=10, callbacks=callbacks_list, verbose=1)\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"/Users/oluwayetty1/Downloads/asmsr_model_stacking2.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights('/Users/oluwayetty1/Downloads/asmsr_weights_stacking2.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "tg = np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_test[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 1, 3, 3, 3, 0, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1,\n",
       "       3, 1, 1, 1, 0, 1, 1, 3, 1, 3, 1, 3, 1, 3, 0, 3, 3, 3, 1, 3, 1, 1,\n",
       "       3, 3, 1, 1, 1, 1, 1, 3, 1, 1, 1, 3, 3, 1, 3, 1, 0, 1, 1, 1, 1, 3,\n",
       "       1, 3, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 3, 3, 1, 1, 0, 1, 3, 1, 1,\n",
       "       3, 1, 3, 3, 1, 1, 3, 1, 0, 1, 1, 0, 1, 1, 1, 3, 1, 1, 1, 3, 1, 1,\n",
       "       1, 1, 1, 3, 1, 1, 3, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 3, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 3, 3, 1, 3, 1, 1, 1, 3, 0, 3, 3, 1, 0, 1, 1, 3,\n",
       "       3, 1, 1, 1, 3, 1, 0, 1, 0, 3, 1, 3, 1, 1, 3, 3, 0, 1, 1, 1, 0, 1,\n",
       "       3, 1, 1, 1, 3, 3, 3, 0, 3, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 3, 3, 3, 1, 1, 1, 3, 1, 1, 0, 1, 3, 1, 1, 1, 1, 1,\n",
       "       1, 1, 3, 3, 0, 1, 3, 1, 1, 1, 1, 1, 1, 1, 0, 1, 3, 0, 1, 1, 1, 1,\n",
       "       1, 3, 1, 1, 3, 1, 3, 3, 3, 3, 1, 3, 1, 1, 1, 1, 3, 0, 3, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 3, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 3, 0, 1, 1, 1, 3, 1, 3, 3, 0, 1, 1, 1, 1, 1, 1, 3,\n",
       "       1, 0, 3, 1, 3, 1, 0, 1, 3, 1, 3, 1, 1, 1, 1, 3, 3, 3, 1, 3, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 3, 1, 3, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 3, 1, 0, 3, 1, 1, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 1, 1, 0, 1, 1, 1, 3, 1, 3, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 0, 0, 1, 1, 3, 3, 1, 3, 1, 3, 0,\n",
       "       3, 3, 3, 1, 1, 1, 1, 1, 0, 1, 1, 1, 3, 1, 3, 1, 1, 3, 1, 1, 1, 3,\n",
       "       1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 0, 1, 3, 3,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 3, 3, 1, 0,\n",
       "       1, 1, 3, 1, 0, 3, 1, 3, 1, 3, 1, 3, 1, 3, 3, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tra[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.88      0.57       225\n",
      "           1       0.60      0.23      0.34       232\n",
      "           2       0.50      0.02      0.04        43\n",
      "           3       0.87      0.62      0.72       200\n",
      "\n",
      "   micro avg       0.54      0.54      0.54       700\n",
      "   macro avg       0.60      0.44      0.42       700\n",
      "weighted avg       0.61      0.54      0.50       700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred, target_names=['0', '1', '2', '3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
